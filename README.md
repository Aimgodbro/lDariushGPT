

```markdown
# DariushGPT: مدل زبانی پیشرفته برای زبان فارسی

DariushGPT یک مدل زبانی مبتنی بر ترانسفورمر است که برای زبان فارسی طراحی شده است. این مدل قابلیت‌های متنوعی مانند تولید متن، تولید شعر و تحلیل احساسات را ارائه می‌دهد و برای استفاده در تحقیقات و کاربردهای عملی بهینه‌سازی شده است.

---

## ویژگی‌های کلیدی

- **تولید متن:** توانایی تولید متن‌های روان و پیوسته به زبان فارسی.
- **تولید شعر:** قابلیت تولید شعر با رعایت وزن عروضی و قافیه.
- **تحلیل احساسات:** تشخیص احساسات متن (مثبت، منفی، خنثی).
- **پشتیبانی از Hugging Face Datasets:** امکان استفاده از دیتاست‌های بزرگ فارسی موجود در Hugging Face.
- **بهینه‌سازی برای سخت‌افزارهای مختلف:** پشتیبانی از CUDA، MPS (برای Apple Silicon) و CPU.
- **آموزش ترکیبی دقت-مختلط (AMP):** افزایش سرعت آموزش با حفظ دقت.
- **ذخیره خودکار بهترین مدل:** ذخیره مدل با کمترین Loss در طول آموزش.

---

## معماری مدل

DariushGPT از یک معماری **ترانسفورمر** با ویژگی‌های زیر استفاده می‌کند:

- **لایه‌های ترانسفورمر:** ۶ لایه با ۸ هد توجه.
- **اندازه امبدینگ:** ۵۱۲ بعدی.
- **اندازه واژگان:** ۳۰٬۰۰۰ توکن.
- **طول دنباله:** حداکثر ۵۱۲ توکن.
- **هدهای تخصصی:** هدهای جداگانه برای تولید متن، شعر و تحلیل احساسات.

---

## نحوه استفاده

### ۱. نصب پیش‌نیازها

برای اجرای کد، ابتدا کتابخانه‌های مورد نیاز را نصب کنید:

```bash
pip install torch tokenizers datasets tqdm
```

### ۲. اجرای آموزش مدل

برای آموزش مدل، کافی است فایل اصلی را اجرا کنید:

```bash
python dariush.py
```

### ۳. استفاده از مدل آموزش‌دیده

پس از آموزش، مدل در فایل `best_dariush_model.pt` ذخیره می‌شود. می‌توانید از این مدل برای تولید متن، شعر یا تحلیل احساسات استفاده کنید.

```python
import torch

# بارگیری مدل
checkpoint = torch.load("best_dariush_model.pt", map_location="cpu")
model = DariushGPT(checkpoint["config"], checkpoint["tokenizer"])
model.load_state_dict(checkpoint["model_state"])

# تولید متن
text = model.generate([model.tokenizer.special_tokens["[BOS]"]])
print(model.tokenizer.decode(text))

# تولید شعر
poem = model.generate_poem(bahr="hazaj", rhyme="ar")
print(model.tokenizer.decode(poem))

# تحلیل احساسات
sentiment = model.analyze_sentiment("این یک شاهکار است!")
print(sentiment)  # مثبت
```

---

## دیتاست‌ها

این پروژه از دیتاست‌های زیر پشتیبانی می‌کند:

- **[OSCAR](https://huggingface.co/datasets/oscar):** دیتاست عمومی فارسی از Hugging Face.
- **[GANJUR](https://github.com/persiannlp/ganjoor):** دیتاست شعر کلاسیک فارسی.
- **[Sentiment Analysis](https://github.com/phosseini/sentiment-persian):** دیتاست تحلیل احساسات فارسی.

---

## بهینه‌سازی‌ها

- **پشتیبانی از MPS:** بهینه‌سازی برای کارت‌های گرافیک Apple Silicon.
- **Gradient Checkpointing:** کاهش مصرف حافظه در طول آموزش.
- **AMP:** آموزش ترکیبی دقت-مختلط برای افزایش سرعت.

---

## نمونه‌های خروجی

### تولید متن
```
زندگی زیباست چون هر لحظه آن پر از شگفتی‌های ناشناخته است...
```

### تولید شعر
```
به نام خداوند جان و خرد
کزین برتر اندیشه برنگذرد
به پیشگاه او سپر اندازم
که از الطافش برخوردارم
```

### تحلیل احساسات
```
متن: "این فیلم واقعا عالی بود!"
احساسات: مثبت
```

---

## پروژه‌های مرتبط

این پروژه از کتابخانه‌ها و دیتاست‌های زیر استفاده کرده است:

- **[PyTorch](https://github.com/pytorch/pytorch):** چارچوب یادگیری عمیق.
- **[Hugging Face Datasets](https://github.com/huggingface/datasets):** کتابخانه برای بارگیری و مدیریت دیتاست‌ها.
- **[Tokenizers](https://github.com/huggingface/tokenizers):** کتابخانه برای توکنایز کردن متن.
- **[GANJUR](https://github.com/persiannlp/ganjoor):** دیتاست شعر فارسی.
- **[Persian Sentiment Analysis](https://github.com/phosseini/sentiment-persian):** دیتاست تحلیل احساسات فارسی.

---

## مشارکت

اگر می‌خواهید در توسعه این پروژه مشارکت کنید، لطفاً مراحل زیر را دنبال کنید:

1. پروژه را Fork کنید.
2. یک Branch جدید ایجاد کنید (`git checkout -b feature/YourFeatureName`).
3. تغییرات خود را Commit کنید (`git commit -m 'Add some feature'`).
4. تغییرات را Push کنید (`git push origin feature/YourFeatureName`).
5. یک Pull Request باز کنید.

---

## لایسنس

این پروژه تحت لایسنس [MIT](LICENSE)

---

## تماس با ما

اگر سوالی دارید یا به کمک نیاز دارید، می‌توانید از طریق ایمیل با ما تماس بگیرید:  
📧 kinhofcod4242@gmail.com

---

**با DariushGPT، قدرت زبان فارسی را کشف کنید!** 🚀


---

مدا بروز رسانی شد ۸ اسفند ۱۴۰۳ 
این کد مدل **DariushGPT** را پیاده‌سازی می‌کند که بر اساس معماری ترانسفورمر ساخته شده و به چندین تسک مختلف پرداخته و قابلیت‌های خاصی برای حل مسائل پیچیده مانند **ترجمه**، **استدلال زنجیره‌ای (Chain-of-Thought)** و **تحلیل احساسات** دارد. در ادامه، ویژگی‌های مختلف کد به تفصیل توضیح داده شده است:

### ۱. **پیکربندی مدل (`DariushConfig`)**
- **پارامترهای مدل**:
  - `vocab_size`: اندازه دیکشنری مدل (۳۰,۰۰۰ کلمه)
  - `emb_size`: ابعاد فضای تعبیه (۵۱۲)
  - `num_heads`: تعداد هدهای توجه در لایه‌های ترانسفورمر (۸)
  - `num_layers`: تعداد لایه‌های ترانسفورمر (۶)
  - `hidden_size`: اندازه فضای پنهان (۲۰۴۸)
  - `max_seq_len`: حداکثر طول دنباله ورودی (۵۱۲)
  
- **تنظیمات آموزش**:
  - `batch_size`: اندازه بچ (۱۶)
  - `learning_rate`: نرخ یادگیری (۳e-۴)
  - `num_epochs`: تعداد دوره‌های آموزش (۱۰)
  - `dropout`: میزان دراپ‌اوت (۰.۱)

- **بهینه‌سازی سخت‌افزاری**:
  - شناسایی دستگاه (CUDA/MPS/CPU) با استفاده از `self._detect_device()`.
  - پشتیبانی از **Mixed Precision Training (AMP)** برای بهبود سرعت و کارایی.
  - **Gradient Checkpointing** برای کاهش مصرف حافظه.
  
- **توکن‌های ویژه**:
  - اضافه شدن توکن‌های خاص برای تسک‌های مختلف، مانند `[COT]` (Chain-of-Thought) و `[TRANS]` (ترجمه).

### ۲. **توکنایزر (`PersianTokenizer`)**
- این کلاس توکنایزر BPE را پیاده‌سازی می‌کند که از **Hugging Face Datasets** برای آموزش استفاده می‌کند.
  - **Training from HF Datasets**: توکنایزر با استفاده از دیتاست‌های فارسی مانند `oscar` آموزش داده می‌شود.
  - **پیش‌پردازش**: از `ByteLevel` برای پیش‌پردازش متن استفاده می‌شود.
  - **ویژگی‌های اصلی**:
    - `encode()`: تبدیل متن به توکن‌ها.
    - `decode()`: تبدیل توکن‌ها به متن.
    - `get_vocab_size()`: دریافت اندازه دیکشنری.
  
### ۳. **دیتاست چندمنظوره (`PersianMultiTaskDataset`)**
- این کلاس دیتاستی برای تسک‌های مختلف مانند **تولید متن**، **شعر** و **تحلیل احساسات** ایجاد می‌کند.
  - **توزیع تسک‌ها**: ۶۰٪ برای متن، ۳۰٪ برای شعر و ۱۰٪ برای احساسات.
  - **روش‌های پردازش**:
    - `_process_text()`: پردازش متن‌های عمومی.
    - `_process_poetry()`: پردازش داده‌های شعر (در این کد پیاده‌سازی نشده است).
    - `_process_sentiment()`: پردازش داده‌های احساسات.
  - **پد کردن دنباله‌ها** با استفاده از توکن‌های `[PAD]` و ماسک توجه برای دنباله‌های کوتاه‌تر از طول حداکثر.

### ۴. **معماری پیشرفته مدل (`DariushGPT`)**
- **المان‌های مدل**:
  - **Embedding**: لایه امبدینگ برای تبدیل توکن‌ها به بردارها.
  - **Positional Encoding**: اضافه کردن اطلاعات موقعیت به توکن‌ها.
  - **Transformer Layers**: استفاده از لایه‌های **Transformer Encoder** برای یادگیری ویژگی‌های پیچیده.
  - **هدهای تخصصی**:
    - `text_head`: هد برای تولید متن.
    - `sentiment_head`: هد برای تحلیل احساسات (طبقه‌بند سه کلاسه).
    - `translation_head`: هد برای ترجمه خودکار.
    - `cot_head`: هد برای استدلال زنجیره‌ای.
  - **پیش‌بینی و انتخاب هد** بر اساس تسک فعلی (متن، احساسات، ترجمه یا استدلال زنجیره‌ای).
  
### ۵. **تولید متن با Chain-of-Thought (`generate_with_cot`)**
- **استدلال زنجیره‌ای (CoT)**:
  - این قابلیت برای حل مسائل پیچیده و انجام استدلال‌های منطقی استفاده می‌شود.
  - اگر توکن `[COT]` در ورودی باشد، مدل به‌طور خودکار وارد حالت استدلال زنجیره‌ای می‌شود.
  - این کار با کمک ماسک توجه و تولید توکن‌های منطقی از مدل صورت می‌گیرد.
  
### ۶. **ترجمه خودکار (`translate`)**
- **ترجمه خودکار**:
  - مدل توانایی ترجمه متن از یک زبان به زبان دیگر را دارد.
  - ورودی شامل توکن `[TRANS]` است که به مدل می‌گوید که باید عمل ترجمه را انجام دهد.
  - ترجمه توسط هد مربوطه ( `translation_head`) انجام می‌شود.
  
### ۷. **سیستم آموزش پیشرفته (`DariushTrainer`)**
- **سیستم آموزش پیشرفته**:
  - استفاده از **Mixed Precision Training (AMP)** برای بهبود سرعت آموزش.
  - **Gradient Accumulation** و **Gradient Checkpointing** برای مدیریت حافظه در پردازش‌های پیچیده.
  - ذخیره بهترین مدل و تولید نمونه‌های آموزشی (متن، شعر، تحلیل احساسات) در هر دوره.
  - **جلوگیری از Overfitting** با استفاده از دراپ‌اوت و تکنیک‌های پیشرفته.

### ۸. **ویژگی‌های اضافی**:
- **پشتیبانی از تسک‌های مختلف**: مدل توانایی انجام **چندین تسک** مانند تولید متن، شعر و تحلیل احساسات را دارد.
- **مدیریت حافظه**: استفاده از **Gradient Checkpointing** برای کاهش مصرف VRAM در هنگام آموزش مدل‌های بزرگ.
- **توسعه و پشتیبانی از سخت‌افزارهای مختلف**: پشتیبانی از **CUDA** (NVIDIA GPU) و **MPS** (برای مک‌های اپل).
  
### **نتیجه‌گیری و بررسی ویژگی‌ها**:
این مدل **DariushGPT** دارای ویژگی‌های پیشرفته‌ای است که آن را قادر می‌سازد به طور همزمان چندین تسک پیچیده از جمله **تولید متن**، **ترجمه خودکار**، **استدلال زنجیره‌ای** و **تحلیل احساسات** را انجام دهد. ویژگی‌های متعددی همچون **پشتیبانی از معماری ترانسفورمر**، **پیش‌بینی بر اساس تسک** و **مدیریت حافظه** برای انجام وظایف پیچیده و بهبود عملکرد مدل به‌کار گرفته شده‌اند.

### **لیست ویژگی‌های کلیدی مدل**:
1. **پشتیبانی از تسک‌های مختلف**:
   - تولید متن
   - تحلیل احساسات
   - ترجمه خودکار
   - استدلال زنجیره‌ای (Chain-of-Thought)
  
2. **توکنایزر پیشرفته**:
   - آموزش از دیتاست‌های فارسی.
   - پشتیبانی از توکن‌های ویژه مانند `[COT]` و `[TRANS]`.

3. **معماری ترانسفورمر پیشرفته**:
   - استفاده از لایه‌های Transformer Encoder.
   - هدهای تخصصی برای هر تسک.

4. **مدیریت حافظه پیشرفته**:
   - **Gradient Checkpointing** برای کاهش مصرف حافظه.
   - پشتیبانی از **Mixed Precision Training (AMP)**.

5. **پشتیبانی از دستگاه‌های مختلف**:
   - پشتیبانی از **CUDA** و **MPS** برای پردازش سریع‌تر.

این کد برای پروژه‌های پیچیده در NLP و AI طراحی شده و با توجه به قابلیت‌های متعدد، می‌تواند به راحتی در حل مسائل مختلف زبانی و علمی استفاده شود.
